# 基于大模型的多模态事实推理核查系统

## 1. 项目简介

本项目是一个基于大语言模型的多模态事实推理核查（fact-checking）系统，旨在自动验证各类声明的真实性。系统采用检索增强生成（RAG）技术构建知识库，显著提高了核查的准确率和可解释性。

## 2. 系统架构

项目采用模块化设计，各组件职责明确，便于理解和维护。整体架构如下：

```
fact_check_system/
├── config/
│   └── config.py              # 配置文件
├── data/ 
│   ├── knowledge_base.jsonl   # 知识库文件
│   └── cache                  # 向量缓存目录
├── models/
│   ├── text_processor.py      # 文本处理模块
│   ├── retriever.py           # 检索模块
│   └── reasoner.py            # 推理模块
├── utils/
│   ├── data_loader.py         # 数据加载工具
│   └── evaluation.py          # 评估工具
├── llm/
│   └── deepseek-r1            # 输出大模型
├── main.py                    # 主程序入口
├── requirements.txt           # 软件包
└── README.md                  # 项目文档
```

## 3. 核心功能模块

### 3.1 文本处理模块 (text_processor.py)

文本处理模块负责对输入查询进行预处理和分析，为后续的检索和推理做准备。主要功能包括：

- **查询预处理**：标准化标点符号、移除多余空格、扩展英文缩写等
- **声明提取**：从用户输入中提取核心声明
- **查询扩展**：生成多个语义相近的查询变体，提高检索召回率
- **关键词提取**：识别查询中的关键词及其重要性
- **语言识别**：自动识别输入是英文还是中文，采用不同的处理策略

该模块针对英文和中文分别进行了优化，能够智能处理各种查询形式。

### 3.2 检索模块 (retriever.py)

检索模块基于RAG技术，负责从知识库中查找与输入查询最相关的事实信息。主要特点：

- **向量化检索**：使用TF-IDF将文本转换为向量表示，进行语义相似度搜索
- **高效缓存机制**：
  - 首次运行时自动将知识库向量化并保存到磁盘
  - 后续运行时如知识库未变，直接加载缓存，避免重复计算
  - 支持基于知识库内容校验和的缓存管理
- **多查询检索**：整合多个查询变体的检索结果，提高系统的召回率
- **英文优化**：针对英文内容使用单词级N-gram和停用词过滤

### 3.3 推理模块 (reasoner.py)

推理模块基于大语言模型，负责分析检索到的相关事实，判断查询声明的真实性。主要功能：

- **提示词生成**：根据查询和检索结果构建结构化提示
- **事实推理**：使用大语言模型分析证据并推理结论
- **结构化输出**：将模型输出解析为标准化格式，包括事实性判断、置信度和解释

推理模块利用思考模式（Thinking Pattern）引导大模型进行逐步推理，提高判断的可靠性。

### 3.4 数据加载工具 (data_loader.py)

数据加载工具负责管理知识库，提供高效的数据访问接口：

- **知识库加载**：从JSONL文件加载知识条目
- **向量存储**：管理文档的向量表示
- **缓存机制**：支持向量索引的持久化存储和加载

## 4. 系统工作流程

整个系统的工作流程如下：

1. **输入处理**：接收用户输入的待核查声明
2. **文本处理**：预处理输入文本，提取核心声明，扩展查询
3. **知识检索**：在知识库中检索相关事实信息
4. **事实推理**：基于检索结果进行推理，判断声明的事实性
5. **结果输出**：返回事实性判断、置信度和解释

## 5. 快速开始

### 5.1 环境准备

项目依赖requirements中的库：

```bash
pip install -r requirements.txt
```

### 5.2 配置说明

系统配置位于 `config/config.py`，主要参数包括：

- `KNOWLEDGE_BASE_PATH`：知识库文件路径
- `RETRIEVAL_TOP_K`：检索返回的条目数量
- `CACHE_DIR`：向量缓存目录
- `LLM_MODEL_PATH`：本地大语言模型路径

### 5.3 知识库格式

知识库文件为JSONL格式，每行包含一个JSON对象，格式如下：

```json
{"claim": "2020年11月30日人民币对美元汇率中间价是否下调了27个基点？", "label": "Factual", "answer": "Yes", "domain": "Multilingual"}
```

### 5.4 使用方法

**核查文本声明：**

```bash
python main.py --query "要核查的声明文本"
```

**使用自定义知识库：**

```bash
python main.py --query "要核查的声明文本" --kb_path "path/to/knowledge_base.jsonl"
```

**强制重建向量索引：**

```bash
python main.py --query "要核查的声明文本" --force_rebuild
```

**清除缓存：**

```bash
python main.py --clear_cache
```

## 6. 高级功能

### 6.1 缓存机制

系统实现了高效的向量缓存机制：

- 首次运行时，系统会将知识库向量化并保存到 `cache` 目录
- 缓存文件以知识库内容的校验和命名，确保知识库变更时能自动重建索引
- 可以使用 `--force_rebuild` 参数强制重建索引
- 可以使用 `--clear_cache` 参数清除所有缓存

### 6.2 多语言支持

系统已针对英文和中文内容进行了优化：

- 英文处理：使用词级分析、英文停用词过滤、单词级别N-gram
- 中文处理：使用jieba分词、中文关键词提取

### 6.3 查询扩展

系统通过生成多种查询变体提高检索效果：

- 使用关键词重组生成新查询
- 英文内容自动转换问句和陈述句形式
- 自动生成语义相近的变体查询